{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httplib2\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from parsel import Selector\n",
    "from statistics import mean\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36\"}\n",
    "http = httplib2.Http()\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from parsel import Selector\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "\n",
    "# configure webdriver\n",
    "options = Options()\n",
    "options.headless = True  # hide GUI\n",
    "options.add_argument(\"--window-size=1920,1080\")  # set window size to native GUI size\n",
    "options.add_argument(\"start-maximized\")  # ensure window is full-screen\n",
    "# configure chrome browser to not load images and javascript\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\n",
    "    \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create database\n",
    "justwatch_tv_db = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"4156\"\n",
    ")\n",
    "\n",
    "mycursor = justwatch_tv_db.cursor()\n",
    "\n",
    "mycursor.execute(\"CREATE DATABASE IF NOT EXISTS justwatch_tv_us_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##connect to db\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Credentials to database connection\n",
    "hostname=\"localhost\"\n",
    "dbname=\"justwatch_tv_us_db\"\n",
    "uname=\"root\"\n",
    "pwd=\"4156\"\n",
    "\n",
    "\n",
    "# Create SQLAlchemy engine to connect to MySQL Database\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "\t\t\t\t.format(host=hostname, db=dbname, user=uname, pw=pwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.justwatch.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python3 Program to Create list \n",
    "# with integers within given range \n",
    "  \n",
    "def createYears(r1, r2):\n",
    "    return [item for item in range(r1, r2+1)]\n",
    "      \n",
    "genres = ['act','cmy',  'doc', 'fnt', 'hrr', 'msc', 'rms', 'spt', 'wsn', 'ani', 'crm', 'drm', 'hst', 'fml', 'trl', 'scf', 'war', 'rly']\n",
    "years = createYears(1900, 2023)\n",
    "\n",
    "\n",
    "search_links = []\n",
    "for i in genres:\n",
    "    for j in years:\n",
    "        link = f\"https://www.justwatch.com/us/tv-shows?genres={i}&release_year_from={j}&release_year_until={j}\"\n",
    "        search_links.append(link)\n",
    "        \n",
    "len(search_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleLinks = []\n",
    "for link in search_links:\n",
    "    print(link)\n",
    "    chrome_options = Options()  \n",
    "    chromedriver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    with chromedriver as browser:\n",
    "        browser.get(link)\n",
    "        time.sleep(5)\n",
    "\n",
    "        last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        SCROLL_PAUSE_TIME = 5\n",
    "        while True:\n",
    "                # Scroll down to bottom\n",
    "                browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                # Wait to load page\n",
    "                time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "                # Calculate new scroll height and compare with last scroll height\n",
    "                new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "                \n",
    "        page_source =browser.page_source\n",
    "        soup=BeautifulSoup(page_source,'html.parser')\n",
    "        productlist = soup.find(\"div\",{\"listlayout\":\"Grid\"})\n",
    "        titles = productlist.find_all(\"div\", {\"class\":\"title-list-grid__item\"})\n",
    "        for title in titles:\n",
    "                    title_link = title.find(\"a\").get('href')\n",
    "                    title_link = base_url+title_link\n",
    "                    if title_link not in titleLinks:\n",
    "                        titleLinks.append(title_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tv_links = pd.DataFrame(titleLinks, columns = ['Title Links'])\n",
    "# Convert dataframe to sql table                                   \n",
    "df_tv_links.to_sql('title_links', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detail(soup_object):\n",
    "    labels  = []\n",
    "    values = []\n",
    "    table_info = soup_object.find(\"div\", {\"class\":\"title-info\"})\n",
    "    rows = table_info.find_all(\"div\", {\"class\":\"detail-infos\"})\n",
    "    for row in rows:\n",
    "        label = row.find(\"div\", {\"class\":\"detail-infos__subheading\"}).text.replace('\\n',\"\")\n",
    "        value = row.find(\"div\", {\"class\":\"detail-infos__value\"}).text.replace('\\n',\"\")\n",
    "        labels.append(label)\n",
    "        values.append(value)\n",
    "        \n",
    "    detail = {labels[i]: values[i] for i in range(len(labels))}\n",
    "        \n",
    "    return detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_cast(soup_object):\n",
    "    cast = []\n",
    "    actors = soup_object.find_all(\"div\", {\"class\":\"title-credits__actor\"})\n",
    "    for actor in actors:\n",
    "        actor_name = actor.text.replace('\\n',\"\")\n",
    "        cast.append(actor_name)\n",
    "    return cast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Pricing:\n",
    "    def __init__(self, soup_object):\n",
    "        self.soup_object = soup_object\n",
    "\n",
    "    def get_stream_options(self):\n",
    "        stream_list = []\n",
    "        price_comparison = self.soup_object.find(\"div\", {\"class\":\"price-comparison--block\"})\n",
    "        price_comparison_stream = price_comparison.find_all(\"div\", {\"class\":\"price-comparison__grid__row price-comparison__grid__row--stream price-comparison__grid__row--block\"})\n",
    "        for comp in price_comparison_stream:\n",
    "            comp = comp.find_all(\"div\", {\"class\":\"price-comparison__grid__row__element\"})\n",
    "            for comp in comp:\n",
    "                service = comp.find(\"img\")\n",
    "                service = service['title']\n",
    "                pricing = comp.find(\"div\", {\"class\":\"price-comparison__grid__row__price\"}).text.replace('\\n',\"\")\n",
    "                stream_options = {service:pricing}\n",
    "                stream_list.append(stream_options)\n",
    "\n",
    "\n",
    "        return stream_list\n",
    "\n",
    "\n",
    "    def get_rent_options(self):\n",
    "        rent_list = []\n",
    "        price_comparison = self.soup_object.find(\"div\", {\"class\":\"price-comparison--block\"})\n",
    "        price_comparison_rent = price_comparison.find_all(\"div\", {\"class\":\"price-comparison__grid__row price-comparison__grid__row--rent price-comparison__grid__row--block\"})\n",
    "        for comp in price_comparison_rent:\n",
    "            comp =  comp.find_all(\"div\", {\"class\":\"price-comparison__grid__row__element\"})\n",
    "            for element in comp:\n",
    "                service = element.find(\"img\")\n",
    "                service = service['title']\n",
    "                pricing = element.find(\"div\", {\"class\":\"price-comparison__grid__row__price\"}).text.replace('\\n',\"\")\n",
    "                rent_options = {service:pricing}\n",
    "                rent_list.append(rent_options)\n",
    "        \n",
    "        return rent_list\n",
    "\n",
    "    def get_buy_options(self):\n",
    "        buy_list = []\n",
    "        price_comparison = self.soup_object.find(\"div\", {\"class\":\"price-comparison--block\"})\n",
    "        price_comparison_buy = price_comparison.find_all(\"div\", {\"class\":\"price-comparison__grid__row price-comparison__grid__row--buy price-comparison__grid__row--block\"})\n",
    "        for comp in price_comparison_buy:\n",
    "            comp = comp.find_all(\"div\", {\"class\":\"price-comparison__grid__row__element\"})\n",
    "            for element in comp:\n",
    "                service = element.find(\"img\")\n",
    "                service = service['title']\n",
    "                pricing = element.find(\"div\", {\"class\":\"price-comparison__grid__row__price\"}).text.replace('\\n',\"\")\n",
    "                buy_options = {service:pricing}\n",
    "                buy_list.append(buy_options)\n",
    "                \n",
    "        return buy_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream_options(soup_object):\n",
    "        stream_list = []\n",
    "        price_comparison = soup_object.find(\"div\", {\"class\":\"price-comparison--block\"})\n",
    "        price_comparison_stream = price_comparison.find_all(\"div\", {\"class\":\"price-comparison__grid__row price-comparison__grid__row--stream price-comparison__grid__row--block\"})\n",
    "        for comp in price_comparison_stream:\n",
    "            comp = comp.find_all(\"div\", {\"class\":\"price-comparison__grid__row__element\"})\n",
    "            for comp in comp:\n",
    "                service = comp.find(\"img\")\n",
    "                service = service['title']\n",
    "                pricing = comp.find(\"div\", {\"class\":\"price-comparison__grid__row__price\"}).text.replace('\\n',\"\")\n",
    "                stream_options = {service:pricing}\n",
    "                stream_list.append(stream_options)\n",
    "        return stream_list\n",
    "\n",
    "\n",
    "def get_rent_options(soup_object):\n",
    "        rent_list = []\n",
    "        price_comparison = soup_object.find(\"div\", {\"class\":\"price-comparison--block\"})\n",
    "        price_comparison_rent = price_comparison.find_all(\"div\", {\"class\":\"price-comparison__grid__row price-comparison__grid__row--rent price-comparison__grid__row--block\"})\n",
    "        for comp in price_comparison_rent:\n",
    "            comp =  comp.find_all(\"div\", {\"class\":\"price-comparison__grid__row__element\"})\n",
    "            for element in comp:\n",
    "                service = element.find(\"img\")\n",
    "                service = service['title']\n",
    "                pricing = element.find(\"div\", {\"class\":\"price-comparison__grid__row__price\"}).text.replace('\\n',\"\")\n",
    "                rent_options = {service:pricing}\n",
    "                rent_list.append(rent_options)\n",
    "        \n",
    "        return rent_list\n",
    "    \n",
    "def get_buy_options(soup_object):\n",
    "        buy_list = []\n",
    "        price_comparison = soup_object.find(\"div\", {\"class\":\"price-comparison--block\"})\n",
    "        price_comparison_buy = price_comparison.find_all(\"div\", {\"class\":\"price-comparison__grid__row price-comparison__grid__row--buy price-comparison__grid__row--block\"})\n",
    "        for comp in price_comparison_buy:\n",
    "            comp = comp.find_all(\"div\", {\"class\":\"price-comparison__grid__row__element\"})\n",
    "            for element in comp:\n",
    "                service = element.find(\"img\")\n",
    "                service = service['title']\n",
    "                pricing = element.find(\"div\", {\"class\":\"price-comparison__grid__row__price\"}).text.replace('\\n',\"\")\n",
    "                buy_options = {service:pricing}\n",
    "                buy_list.append(buy_options)\n",
    "                \n",
    "        return buy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best(driver):\n",
    "            driver.implicitly_wait(0.5)\n",
    "            '''\n",
    "            best = WebDriverWait(driver=driver, timeout=5).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"base\"]/div[2]/div/div[2]/div[2]/div[3]/div/div[2]/div/div[1]/div[1]/div/div[1]'))\n",
    "            )\n",
    "            best.click()\n",
    "            \n",
    "            time.sleep(5)\n",
    "            '''\n",
    "            \n",
    "            page_source =driver.page_source\n",
    "            hun=BeautifulSoup(page_source,'html.parser')\n",
    "            stream_best = get_stream_options(hun)\n",
    "            buy_best = get_buy_options(hun)\n",
    "            rent_best = get_rent_options(hun)\n",
    "            \n",
    "            options = {\"stream_best\": stream_best,\n",
    "                    \"rent_best\":rent_best,\n",
    "                    \"buy_best\":buy_best}\n",
    "            \n",
    "            return options\n",
    "        \n",
    "def get_free(driver, bts):\n",
    "            time.sleep(5)\n",
    "            bts[1].click()\n",
    "            \n",
    "            time.sleep(5)\n",
    "            \n",
    "            page_source =driver.page_source\n",
    "            hun=BeautifulSoup(page_source,'html.parser')\n",
    "            stream_free = get_stream_options(hun)\n",
    "            buy_free = get_buy_options(hun)\n",
    "            rent_free = get_rent_options(hun)\n",
    "            \n",
    "            \n",
    "            options = {\"stream_free\": stream_free,\n",
    "                    \"rent_free\":rent_free,\n",
    "                    \"buy_free\":buy_free}\n",
    "        \n",
    "            return options\n",
    "        \n",
    "def get_sd(driver, bts):\n",
    "            driver.implicitly_wait(0.5)\n",
    "            bts[2].click()\n",
    "            \n",
    "            time.sleep(5)\n",
    "            \n",
    "            page_source =driver.page_source\n",
    "            hun=BeautifulSoup(page_source,'html.parser')\n",
    "            stream_sd = get_stream_options(hun)\n",
    "            buy_sd = get_buy_options(hun)\n",
    "            rent_sd = get_rent_options(hun)\n",
    "            \n",
    "            options = {\"stream_sd\": stream_sd,\n",
    "                    \"rent_sd\":rent_sd,\n",
    "                    \"buy_sd\":buy_sd}\n",
    "        \n",
    "            return options\n",
    "        \n",
    "def get_hd(driver, bts):\n",
    "        driver.implicitly_wait(0.5)\n",
    "            \n",
    "        bts[3].click()\n",
    "            \n",
    "            \n",
    "        time.sleep(5)\n",
    "            \n",
    "        page_source =driver.page_source\n",
    "        \n",
    "        hun=BeautifulSoup(page_source,'html.parser')\n",
    "        stream_hd = get_stream_options(hun)\n",
    "        buy_hd = get_buy_options(hun)\n",
    "        rent_hd = get_rent_options(hun)\n",
    "            \n",
    "        options = {\"stream_hd\": stream_hd,\n",
    "                    \"rent_hd\":rent_hd,\n",
    "                    \"buy_hd\":buy_hd}\n",
    "        \n",
    "        return options\n",
    "        \n",
    "      \n",
    "def get_4k(driver, bts):   \n",
    "        driver.implicitly_wait(0.5)\n",
    "        bts[4].click()\n",
    "            \n",
    "        time.sleep(5)\n",
    "            \n",
    "        page_source =  driver.page_source\n",
    "        hun=BeautifulSoup(page_source,'html.parser')\n",
    "        stream_4k = get_stream_options(hun)\n",
    "        buy_4k = get_buy_options(hun)\n",
    "        rent_4k = get_rent_options(hun)       \n",
    "            \n",
    "        options = {\"stream_4k\": stream_4k,\n",
    "                    \"rent_4k\":rent_4k,\n",
    "                    \"buy_4k\":buy_4k}\n",
    "        \n",
    "        return options\n",
    "\n",
    "def get_season_links(driver, link):\n",
    "        season_links = []\n",
    "        driver.implicitly_wait(1)\n",
    "        tvs = driver.find_elements(By.XPATH, '//*[@id=\"base\"]/div[2]/div/div[2]/div[2]/div[2]/div[2]/div/div/div')\n",
    "        tv_sns = WebDriverWait(driver=driver, timeout=5).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, '//*[@id=\"base\"]/div[2]/div/div[2]/div[2]/div[2]/div[2]/div/div/div'))\n",
    "                        )\n",
    "        sel = Selector(text=driver.page_source)\n",
    "        tvs = sel.xpath('//*[@id=\"base\"]/div[2]/div/div[2]/div[2]/div[2]/div[2]/div/div/div')\n",
    "        for tv in tvs:\n",
    "                tv_links = tv.css('::attr(href)').getall()\n",
    "                for l in tv_links:\n",
    "                        season_link  = base_url+l\n",
    "                        sn_link = {\"season_link\":season_link,\n",
    "                            \"tv_link\":link}\n",
    "                        season_links.append(sn_link)\n",
    "                \n",
    "        return season_links\n",
    "\n",
    "def get_synopsis(driver):     \n",
    "    synopsis = driver.find_element(By.XPATH, '//*[@id=\"base\"]/div[2]/div/div[2]/div[2]/div[2]/div[2]/div[2]/p').text\n",
    "    return synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(titleLinks):\n",
    "    data = []\n",
    "    for link in titleLinks:\n",
    "            driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "            with driver as driver:\n",
    "                driver.get(link)\n",
    "                \n",
    "                banner = WebDriverWait(driver=driver, timeout=5).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, '//*[@id=\"app\"]/div[5]/div[2]/div[2]/button[1]'))\n",
    "                    )\n",
    "                \n",
    "                banner.click()\n",
    "                \n",
    "                time.sleep(1)\n",
    "                bts = driver.find_elements(By.CLASS_NAME,'jw-chip-button')\n",
    "                \n",
    "                try:\n",
    "                    imdb_link = WebDriverWait(driver=driver, timeout=5).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, '//*[@id=\"base\"]/div[2]/div/div[1]/div/aside/div[1]/div[3]/div[1]/div[2]/div/div[2]/a'))\n",
    "                    )\n",
    "               \n",
    "                    imdb_link = imdb_link.get_attribute('href')\n",
    "                except:\n",
    "                    imdb_link = None\n",
    "                \n",
    "                page_source =  driver.page_source\n",
    "                \n",
    "                hun=BeautifulSoup(page_source,'html.parser')\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    detail = get_detail(hun)\n",
    "                except:\n",
    "                    detail = None\n",
    "                    \n",
    "                try:\n",
    "                    title_name = hun.find(\"div\", {\"class\":\"title-block\"})\n",
    "                    title_name = title_name.find(\"h1\").text.replace('\\n',\"\")\n",
    "                except:\n",
    "                    title_name = None\n",
    "                    \n",
    "                try:\n",
    "                    season_1_year = hun.find(\"span\", {\"class\":\"text-muted\"}).text.replace('\\n',\"\")\n",
    "                except:\n",
    "                    year = None\n",
    "                \n",
    "                try:\n",
    "                    prices_best = get_best(driver)\n",
    "                except:\n",
    "                    prices_best = None\n",
    "                \n",
    "                try:\n",
    "                    prices_free = get_free(driver,bts)\n",
    "                except:\n",
    "                    prices_free = None\n",
    "                    \n",
    "                try:\n",
    "                    prices_sd = get_sd(driver, bts)\n",
    "                except:\n",
    "                    prices_sd = None\n",
    "                    \n",
    "                try:\n",
    "                    prices_hd = get_hd(driver, bts)\n",
    "                except:\n",
    "                    prices_hd = None\n",
    "                    \n",
    "                try:   \n",
    "                    prices_4k = get_4k(driver, bts)\n",
    "                except:\n",
    "                    prices_4k = None\n",
    "\n",
    "                try:\n",
    "                    season_urls = get_season_links(driver, link)\n",
    "                except:\n",
    "                    season_urls = None\n",
    "        \n",
    "                title_url = link\n",
    "                \n",
    "                tv = {\"title\":title_name, \"season_1_year\":season_1_year, \"season_urls\":season_urls,\"detail\":detail, \"4k prices\":prices_4k, \"hd prices\":prices_hd, \"sd prices\":prices_sd, \"free\":prices_free, \"best prices\":prices_best,\"imdb_link\":imdb_link,\"title_url\": title_url}\n",
    "        \n",
    "                data.append(tv)\n",
    "        \n",
    "    return  data\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = get_data(titleLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(Data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_df = df['4k prices'].apply(pd.Series)\n",
    "h_df = df['hd prices'].apply(pd.Series)\n",
    "s_df = df['sd prices'].apply(pd.Series)\n",
    "f_df = df['free'].apply(pd.Series)\n",
    "b_df = df['best prices'].apply(pd.Series)\n",
    "d_df = df['detail'].apply(pd.Series)\n",
    "d_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['season_urls']\n",
    "season_links_df = df['season_urls'].apply(pd.Series)\n",
    "df_sns = pd.json_normalize(season_links_df[0])\n",
    "df_sns = pd.concat([df_sns, df['season_1_year'].reindex(df.index)], axis=1)\n",
    "df_sns.to_sql('justwatch_season_urls', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, k_df.reindex(df.index)], axis=1)\n",
    "df = pd.concat([df, h_df.reindex(df.index)], axis=1)\n",
    "df = pd.concat([df, s_df.reindex(df.index)], axis=1)\n",
    "df = pd.concat([df, f_df.reindex(df.index)], axis=1)\n",
    "df = pd.concat([df, b_df.reindex(df.index)], axis=1)\n",
    "df = pd.concat([df, d_df.reindex(df.index)], axis=1)\n",
    "\n",
    "df_c = df.drop(['4k prices', 'hd prices', 'sd prices', 'free', 'best prices', 'detail', 'season_1_year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_c.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.to_sql('justwatch_data', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c.to_csv(\"tv.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
