{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from parsel import Selector\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# configure webdriver\n",
    "options = Options()\n",
    "options.headless = True  # hide GUI\n",
    "options.add_argument(\"--window-size=1920,1080\")  # set window size to native GUI size\n",
    "options.add_argument(\"start-maximized\")  # ensure window is full-screen\n",
    "# configure chrome browser to not load images and javascript\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\n",
    "    \"prefs\", {\"profile.managed_default_content_settings.images\": 2}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httplib2\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from parsel import Selector\n",
    "from statistics import mean\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36\"}\n",
    "http = httplib2.Http()\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create database\n",
    "mitv_db = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  password=\"4156\"\n",
    ")\n",
    "\n",
    "mycursor = mitv_db.cursor()\n",
    "\n",
    "mycursor.execute(\"CREATE DATABASE IF NOT EXISTS mitv_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##connect to db\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Credentials to database connection\n",
    "hostname=\"localhost\"\n",
    "dbname=\"mitv_db\"\n",
    "uname=\"root\"\n",
    "pwd=\"4156\"\n",
    "\n",
    "\n",
    "# Create SQLAlchemy engine to connect to MySQL Database\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "\t\t\t\t.format(host=hostname, db=dbname, user=uname, pw=pwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_3288\\1503906442.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://mi.tv/br/entrar\"\n",
    "driver.get(url)\n",
    "driver.window_handles;\n",
    "driver.find_element(By.CSS_SELECTOR, \"body\").send_keys(Keys.CONTROL+\"t\");\n",
    "driver.find_element(By.XPATH, '//*[@id=\"login-email\"]').send_keys(\"osumorog@gmail.com\")\n",
    "driver.find_element(By.XPATH, '//*[@id=\"login-password\"]').send_keys(\"firefire\")\n",
    "driver.find_element(By.XPATH, '//*[@id=\"btn-email-login-perform\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set implicit wait time\n",
    "import time\n",
    "driver.implicitly_wait(10) # seconds\n",
    "time.sleep(5)\n",
    "driver.get(\"https://mi.tv/br/perfil/selecionar-canais\")\n",
    "\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "SCROLL_PAUSE_TIME = 5\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "page_source =driver.page_source\n",
    "soup = BeautifulSoup(page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825\n"
     ]
    }
   ],
   "source": [
    "buttons = soup.find(\"div\", {\"class\":\"container\"})\n",
    "buttons = buttons.find_all(\"span\",{\"class\":\"channel-name\"})\n",
    "channel_names = []\n",
    "for button in buttons:\n",
    "    channel_names.append(button.text.replace('\\n',\"\"))\n",
    "    \n",
    "for i in range(1, len(channel_names[1:])):\n",
    "    channel_names[i] = channel_names[i] .replace(\"+\", \"\")\n",
    "    channel_names[i] = channel_names[i] .replace(\"&\", \"_\")\n",
    "    channel_names[i] = channel_names[i] .replace(\"-\", \"\")\n",
    "    channel_names[i] = channel_names[i] .replace(\"!\", \"_!\") \n",
    "    channel_names[i] = channel_names[i] .replace(\"'\", \"_\") \n",
    "    channel_names[i] = channel_names[i] .replace(\"(\", \"_\") \n",
    "    channel_names[i] = channel_names[i] .replace(\")\", \"_\") \n",
    "print(len(channel_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824\n"
     ]
    }
   ],
   "source": [
    "search_urls = []\n",
    "links = []\n",
    "base_url =\"https://mi.tv\"\n",
    "for i in channel_names[1:]:\n",
    "    search_link = 'https://mi.tv/br/pesquisar/'+i\n",
    "    search_urls.append(search_link)\n",
    "    \n",
    "print(len(search_urls))\n",
    "\n",
    "for i in search_urls:    \n",
    "    driver.get(i)\n",
    "    page_source =driver.page_source\n",
    "    soup = BeautifulSoup(page_source,'html.parser')\n",
    "    channel_links = soup.find(\"ul\", {\"class\":\"channels\"})\n",
    "    if channel_links !=None:\n",
    "        is_scraped = 1\n",
    "        channel_links = channel_links.find_all(\"li\")\n",
    "        for channel_link in channel_links:\n",
    "            tv_link = channel_link.find(\"a\").get(\"href\")\n",
    "            tv_link = base_url+tv_link\n",
    "            if tv_link not in links:\n",
    "                links.append(tv_link)\n",
    "\n",
    "    else:\n",
    "        print(f'check channel link: {i}')\n",
    "        is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing links in db table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channel_links = pd.DataFrame(links, columns = ['Channel Links'])\n",
    "# Convert dataframe to sql table                                   \n",
    "df_channel_links.to_sql('channel_links', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slink = \"https://mi.tv/br/canais/amc-hd/2022-09-01\"\n",
    "driver.get(slink)\n",
    "page_source =driver.page_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Data:\n",
    "    def __init__(self, link, date):\n",
    "        self.driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "        self.link = link+\"/\"+date\n",
    "\n",
    "    def get_data(self):\n",
    "        from datetime import datetime\n",
    "        self.driver.get(self.link)\n",
    "        page_source =self.driver.page_source\n",
    "        soup = BeautifulSoup(page_source,'html.parser')\n",
    "        try:\n",
    "            channel_detail = soup.find(\"div\", {\"class\":\"channel-info\"})\n",
    "        except:\n",
    "            channel_detail = None\n",
    "        try:\n",
    "            channel_name = channel_detail.find(\"h1\").text.replace('\\n',\"\")\n",
    "        except:\n",
    "            channel_name = None\n",
    "        try:\n",
    "            program_date = channel_detail.find(\"span\").text.replace('\\n',\"\")\n",
    "        except:\n",
    "            program_date = None\n",
    "        try:\n",
    "            programs = soup.find(\"ul\", {\"class\":\"broadcasts time24\"})\n",
    "        except:\n",
    "            programs  =None\n",
    "        try:\n",
    "            programs = programs.find_all(\"li\")\n",
    "        except:\n",
    "            programs  =None\n",
    "        for program in programs:\n",
    "            content = program.find(\"div\", {\"class\":\"content\"})\n",
    "            try:\n",
    "                prog_link = program.find(\"a\", {\"class\":\"program-link\"}).get(\"href\")   \n",
    "            except:\n",
    "                prog_link = None\n",
    "            try:\n",
    "                prog_name = content.find(\"h2\").text.replace('\\n',\"\")\n",
    "                prog_name = re.sub(r\"[\\t]*\", \"\", prog_name)\n",
    "            except:\n",
    "                prog_name = None\n",
    "                \n",
    "            try:\n",
    "                prog_time = content.find(\"span\", {\"class\":\"time\"}).text.replace('\\n',\"\")\n",
    "            except:\n",
    "                prog_time = None\n",
    "            try:\n",
    "                prog_genre = content.find(\"span\", {\"class\":\"sub-title\"}).text.replace('\\n',\"\")\n",
    "                prog_genre = re.sub(r\"[\\t]*\", \"\", prog_genre)\n",
    "            except:\n",
    "                prog_genre = None\n",
    "            try:\n",
    "                prog_synopsis = content.find(\"p\", {\"class\":\"synopsis\"}).text.replace('\\n',\"\")\n",
    "                prog_synopsis = re.sub(r\"[\\t]*\", \"\", prog_synopsis)\n",
    "            except:\n",
    "                prog_synopsis = None\n",
    "                \n",
    "            try:\n",
    "                now = datetime.now()\n",
    "                date_scraped = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "            except:\n",
    "                date_scraped = None\n",
    "            \n",
    "            tv = {\"channel\":channel_name, \"program name\":prog_name, \"program time\":prog_time,\"program genre\":prog_genre, \"program synopsis\":prog_synopsis, \"program link\":prog_link,  \"date\":program_date, \"scraped link\":self.link, \"scrape date\":date_scraped}\n",
    "            \n",
    "            return tv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "data = []\n",
    "for link in links:\n",
    "    driver.get(link)\n",
    "    page_source =driver.page_source\n",
    "    soup = BeautifulSoup(page_source,'html.parser')\n",
    "    \n",
    "    programs = soup.find(\"ul\", {\"class\":\"broadcasts time24\"})\n",
    "    if programs != None:\n",
    "        programs = programs.find_all(\"li\")\n",
    "        for program in programs:\n",
    "            content = program.find(\"div\", {\"class\":\"content\"})\n",
    "            channel_detail = soup.find(\"div\", {\"class\":\"channel-info\"})\n",
    "            try:\n",
    "                channel_name = channel_detail.find(\"h1\").text.replace('\\n',\"\")\n",
    "            except:\n",
    "                channel_name = None\n",
    "            try:\n",
    "                program_date = channel_detail.find(\"span\").text.replace('\\n',\"\")\n",
    "            except:\n",
    "                program_date = None\n",
    "            try:\n",
    "                prog_link = program.find(\"a\", {\"class\":\"program-link\"}).get(\"href\")   \n",
    "            except:\n",
    "                prog_link = None\n",
    "            try:\n",
    "                prog_name = content.find(\"h2\").text.replace('\\n',\"\")\n",
    "                prog_name = re.sub(r\"[\\t]*\", \"\", prog_name)\n",
    "            except:\n",
    "                prog_name = None\n",
    "                        \n",
    "            try:\n",
    "                prog_time = content.find(\"span\", {\"class\":\"time\"}).text.replace('\\n',\"\")\n",
    "            except:\n",
    "                prog_time = None\n",
    "            try:\n",
    "                prog_genre = content.find(\"span\", {\"class\":\"sub-title\"}).text.replace('\\n',\"\")\n",
    "                prog_genre = re.sub(r\"[\\t]*\", \"\", prog_genre)\n",
    "            except:\n",
    "                prog_genre = None\n",
    "            try:\n",
    "                prog_synopsis = content.find(\"p\", {\"class\":\"synopsis\"}).text.replace('\\n',\"\")\n",
    "                prog_synopsis = re.sub(r\"[\\t]*\", \"\", prog_synopsis)\n",
    "            except:\n",
    "                prog_synopsis = None\n",
    "                        \n",
    "            try:\n",
    "                now = datetime.now()\n",
    "                date_scraped = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "            except:\n",
    "                date_scraped = None\n",
    "                    \n",
    "            tv = {\"channel\":channel_name, \"program name\":prog_name, \"program time\":prog_time,\"program genre\":prog_genre, \"program synopsis\":prog_synopsis, \"program link\":prog_link,  \"date\":program_date, \"scraped link\":link, \"scrape date\":date_scraped}\n",
    "                    \n",
    "            data.append(tv)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###For a single date use above\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For  a range of Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "start_date = date(2022, 8, 2) \n",
    "end_date = date(2022, 9, 2)    # perhaps date.now()\n",
    "\n",
    "def get_range_links(links, start_date, end_date):\n",
    "    dates = []\n",
    "    scrape_links = []\n",
    "    from datetime import date, timedelta\n",
    "    delta = end_date - start_date   # returns timedelta\n",
    "    for i in links:\n",
    "        for j in range(delta.days + 1):\n",
    "            day = start_date + timedelta(days=j)\n",
    "            day = day.strftime('%Y-%m-%d')\n",
    "            scrape_links.append(i+\"/\"+day)\n",
    "    \n",
    "    return scrape_links\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "811"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "start_date = date(2022, 8, 2) \n",
    "end_date = date(2022, 8, 10) \n",
    "scrape_links = get_range_links(links, start_date, end_date)\n",
    "scrape_links\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(scrape_links):\n",
    "    from datetime import datetime\n",
    "    scrape_links = scrape_links\n",
    "    data = []\n",
    "    for link in scrape_links:\n",
    "        is_scraped = 0\n",
    "        driver.get(link)\n",
    "        page_source =driver.page_source\n",
    "        soup = BeautifulSoup(page_source,'html.parser')\n",
    "        \n",
    "        programs = soup.find(\"ul\", {\"class\":\"broadcasts time24\"})\n",
    "        if programs != None:\n",
    "            programs = programs.find_all(\"li\")\n",
    "            for program in programs:\n",
    "                content = program.find(\"div\", {\"class\":\"content\"})\n",
    "                channel_detail = soup.find(\"div\", {\"class\":\"channel-info\"})\n",
    "                try:\n",
    "                    channel_name = channel_detail.find(\"h1\").text.replace('\\n',\"\")\n",
    "                except:\n",
    "                    channel_name = None\n",
    "                try:\n",
    "                    program_date = channel_detail.find(\"span\").text.replace('\\n',\"\")\n",
    "                except:\n",
    "                    program_date = None\n",
    "                try:\n",
    "                    prog_link = program.find(\"a\", {\"class\":\"program-link\"}).get(\"href\")   \n",
    "                except:\n",
    "                    prog_link = None\n",
    "                try:\n",
    "                    prog_name = content.find(\"h2\").text.replace('\\n',\"\")\n",
    "                    prog_name = re.sub(r\"[\\t]*\", \"\", prog_name)\n",
    "                except:\n",
    "                    prog_name = None\n",
    "                            \n",
    "                try:\n",
    "                    prog_time = content.find(\"span\", {\"class\":\"time\"}).text.replace('\\n',\"\")\n",
    "                except:\n",
    "                    prog_time = None\n",
    "                try:\n",
    "                    prog_genre = content.find(\"span\", {\"class\":\"sub-title\"}).text.replace('\\n',\"\")\n",
    "                    prog_genre = re.sub(r\"[\\t]*\", \"\", prog_genre)\n",
    "                except:\n",
    "                    prog_genre = None\n",
    "                try:\n",
    "                    prog_synopsis = content.find(\"p\", {\"class\":\"synopsis\"}).text.replace('\\n',\"\")\n",
    "                    prog_synopsis = re.sub(r\"[\\t]*\", \"\", prog_synopsis)\n",
    "                except:\n",
    "                    prog_synopsis = None\n",
    "                            \n",
    "                try:\n",
    "                    now = datetime.now()\n",
    "                    date_scraped = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                except:\n",
    "                    date_scraped = None\n",
    "                        \n",
    "                tv = {\"channel\":channel_name, \"program name\":prog_name, \"program time\":prog_time,\"program genre\":prog_genre, \"program synopsis\":prog_synopsis, \"program link\":prog_link,  \"date\":program_date, \"scraped link\":link, \"scrape date\":date_scraped}\n",
    "                        \n",
    "                data.append(tv)\n",
    "                \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_range = get_data(scrape_links = get_range_links(links, start_date, end_date))\n",
    "data_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_range = pd.DataFrame.from_dict(data_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to sql table                                   \n",
    "df_range.to_sql('data_table',  engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_range.to_csv(\"mi_tv_range.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
